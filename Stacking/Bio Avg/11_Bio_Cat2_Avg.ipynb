{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_av_tr = pd.read_csv('Test_Datasets/11_Bio_Cat2_Avg_training.csv')\n",
    "bio_av_vl = pd.read_csv('Test_Datasets/11_Bio_Cat2_Avg_validation.csv')\n",
    "bio_av_ev = pd.read_csv('Test_Datasets/11_Bio_Cat2_Avg_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features and target variables\n",
    "\n",
    "def x_y(df):\n",
    "    y = df['0']\n",
    "    x = df.drop(columns=['0'])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ba_tr, y_ba_tr = x_y(bio_av_tr)\n",
    "x_ba_vl, y_ba_vl = x_y(bio_av_vl)\n",
    "x_ba_ev, y_ba_ev = x_y(bio_av_ev)\n",
    "#x_ba_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate model on dataset\n",
    "import time\n",
    "\n",
    "def scorer(model, x_ts, y_ts, name = 'Model'):\n",
    "    print(' {} \\n Score: {:6.4f}'.format(name, model.score(x_ts, y_ts)))\n",
    "\n",
    "def trainer(model, x_tr, y_tr, x_vl, y_vl, x_ev, y_ev, name='Model'):\n",
    "    st = time.time()\n",
    "    model.fit(x_tr, y_tr)\n",
    "    print('Training time: {:6.4f} s\\n'.format(time.time()-st))\n",
    "    scorer(mod_gs, x_vl, y_vl, '\\n{} : Cross Validation Score:'.format(name))\n",
    "    scorer(mod_gs, x_ev, y_ev, '{} : Evaluation Set Score:'.format(name))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train with GridSearch\n",
    "\n",
    "def trainer_gs(mod, params, x_tr, y_tr, x_vl, y_vl, x_ev, y_ev, cvl, name='Model'):\n",
    "    start = time.time()\n",
    "    mod_gs = GridSearchCV(mod, params, cv=cvl)\n",
    "    mod_gs.fit(x_tr, y_tr)\n",
    "    print('Training Time : {:6.4f} seconds'.format(time.time()-start))\n",
    "    print('\\nOptimal parameter:\\n', mod_gs.best_params_)\n",
    "    \n",
    "    mod_fin = mod_gs.best_estimator_\n",
    "    \n",
    "    scorer(mod_gs, x_vl, y_vl, '\\n{} : Cross Validation Score:'.format(name))\n",
    "    scorer(mod_gs, x_ev, y_ev, '{} : Evaluation Set Score:'.format(name))\n",
    "    return mod_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.8211 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# lr = trainer(lr, x_ba_tr, y_ba_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model \n",
      " Score: 0.9875\n",
      " Model \n",
      " Score: 0.8200\n"
     ]
    }
   ],
   "source": [
    "#lr = trainer(lr, x_ba_vl, y_ba_vl)\n",
    "\n",
    "scorer(lr, x_ba_vl, y_ba_vl)\n",
    "scorer(lr, x_ba_ev, y_ba_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pickle a trained model to an output.pickle file\n",
    "import pickle\n",
    "\n",
    "def pkl_out(model, name='Model'):\n",
    "    op_ = open(\"Pkls/{}.pickle\".format(name), \"wb\")\n",
    "    pickle.dump(model, op_)\n",
    "    op_.close()\n",
    "    print('Success')\n",
    "    \n",
    "# Function to extract a trained model from a pickle file\n",
    "\n",
    "def pkl_in(name):\n",
    "    ip_ = open(\"Pkls/{}.pickle\".format(name), \"rb\")\n",
    "    mod = pickle.load(ip_)\n",
    "    return mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hereon, we try different classifiers with a range of parameters for accuracy, followed by ensembles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time : 25.4586 seconds\n",
      "\n",
      "Optimal parameter:\n",
      " {'max_iter': 300}\n",
      " \n",
      "Logistic Regression : Cross Validation Score: \n",
      " Score: 0.9875\n",
      " Logistic Regression : Evaluation Set Score: \n",
      " Score: 0.8200\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "params_lr = {'max_iter':[300, 500, 750]}\n",
    "\n",
    "lr_f = trainer_gs(lr, params_lr, x_ba_tr, y_ba_tr, x_ba_vl, y_ba_vl, x_ba_ev, y_ba_ev, 5, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time : 310.5012 seconds\n",
      "\n",
      "Optimal parameter:\n",
      " {'n_neighbors': 2}\n",
      " \n",
      "K Nearest Neighbors : Cross Validation Score: \n",
      " Score: 0.9563\n",
      " K Nearest Neighbors : Evaluation Set Score: \n",
      " Score: 0.7664\n"
     ]
    }
   ],
   "source": [
    "# 2. K Nearest Neighbors\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "params_knn = {'n_neighbors': np.arange(1,25)}\n",
    "\n",
    "knn_f = trainer_gs(knn, params_knn, x_ba_tr, y_ba_tr, x_ba_vl, y_ba_vl, x_ba_ev, y_ba_ev, 5, 'K Nearest Neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time : 84.9117 seconds\n",
      "\n",
      "Optimal parameter:\n",
      " {'n_estimators': 150}\n",
      " \n",
      "Random Forest : Cross Validation Score: \n",
      " Score: 0.9750\n",
      " Random Forest : Evaluation Set Score: \n",
      " Score: 0.7243\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "params_rf = {'n_estimators':[10, 50, 100, 150, 200, 250]}\n",
    "rf_f = trainer_gs(rf, params_rf, x_ba_tr, y_ba_tr, x_ba_vl, y_ba_vl, x_ba_ev, y_ba_ev, 5, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time : 49.9612 seconds\n",
      "\n",
      "Optimal parameter:\n",
      " {'max_iter': 300}\n",
      " \n",
      "Support Vector : Cross Validation Score: \n",
      " Score: 0.9812\n",
      " Support Vector : Evaluation Set Score: \n",
      " Score: 0.7936\n"
     ]
    }
   ],
   "source": [
    "# 4. Support Vector\n",
    "\n",
    "sv = SVC()\n",
    "params_sv = {'max_iter':[300, 400, 500, 600, 750]}\n",
    "\n",
    "sv_f = trainer_gs(sv, params_sv, x_ba_tr, y_ba_tr, x_ba_vl, y_ba_vl, x_ba_ev, y_ba_ev, 5, 'Support Vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Pickling final tuned models\n",
    "\n",
    "pkl_out(lr_f, \"LogReg\")\n",
    "pkl_out(knn_f, \"KNeighbors\")\n",
    "pkl_out(rf_f, \"RandomForest\")\n",
    "pkl_out(sv_f, \"SupportVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['lr', 'knn', 'rf', 'sv']\n",
    "\n",
    "models = [('lr', lr_f), ('knn', knn_f), ('rf', rf_f), ('sv', sv_f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  14.33 s\n",
      " Ensemble: Hard voting \n",
      " Score: 0.7893\n"
     ]
    }
   ],
   "source": [
    "vot_h = VotingClassifier(models, voting='hard')\n",
    "\n",
    "st=time.time()\n",
    "vot_h.fit(x_ba_tr, y_ba_tr)\n",
    "print('Training time: {:6.2f} s'.format(time.time()-st))\n",
    "\n",
    "scorer(vot_h, x_ba_ev, y_ba_ev, 'Ensemble: Hard voting')\n",
    "\n",
    "\n",
    "# st=time.time()\n",
    "# ens_s.fit(x_ba_tr, y_ba_tr)\n",
    "# print('Training time: {:6.2f} s'.format(time.time()-st))\n",
    "\n",
    "#scorer(ens_s, x_ba_ev, y_ba_ev, 'Ensemble: Soft voting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  87.27 s\n",
      " Ensemble: Stacking \n",
      " Score: 0.8100\n"
     ]
    }
   ],
   "source": [
    "stk = StackingClassifier(models)\n",
    "\n",
    "\n",
    "x_ba_trvl.dropna(axis=0)\n",
    "\n",
    "st=time.time()\n",
    "stk.fit(x_ba_tr, y_ba_tr)\n",
    "print('Training time: {:6.2f} s'.format(time.time()-st))\n",
    "\n",
    "scorer(stk, x_ba_ev, y_ba_ev, 'Ensemble: Stacking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "pkl_out(vot_h, \"Voting\")\n",
    "pkl_out(stk, \"Stacked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
